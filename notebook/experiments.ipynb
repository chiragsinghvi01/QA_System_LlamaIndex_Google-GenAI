{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e6e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Environment Variables and API Key\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10103179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve Google API Key from Environment\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4e792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "#Validate Google API Key\n",
    "\n",
    "if google_api_key is None:\n",
    "    print(\"Google API key not found. Please set the GOOGLE_API_KEY environment variable.\")\n",
    "else:\n",
    "    print(\"Google API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47219b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required Libraries\n",
    "\n",
    "from llama_index.core import (VectorStoreIndex, SimpleDirectoryReader,\n",
    "                              StorageContext, load_index_from_storage)\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google import genai\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc19eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Google Generative AI Client\n",
    "\n",
    "client = genai.Client(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all available Models\n",
    "\n",
    "for model in client.models.list():\n",
    "    display(Markdown(f\" *Model*: {model.name} | {model.supported_actions}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List Models that support `generateContent`\n",
    "\n",
    "for model in client.models.list():\n",
    "    if 'generateContent' in model.supported_actions:\n",
    "        display(Markdown(f\" *Model*: {model.name} | {model.supported_actions}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98fef4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1956bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = documents.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d3f4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This dataset provides an extensive collection of general knowledge, formatted into detailed descriptive paragraphs, suitable for training or testing a comprehensive Question Answering (QA) system.\r\n",
       "\r\n",
       "Category: History\r\n",
       "History encompasses the systematic study of past events, particularly in human affairs, often relying on critical analysis of primary sources (such as documents, artifacts, and eyewitness accounts) and secondary sources (interpretations by historians), alongside archaeological findings and oral traditions. George Washington, a figure of immense significance in American history, "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"{docs[0].text[:600]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af85ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogleGenAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbcd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2fc9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = model\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 1000\n",
    "Settings.chunk_overlap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04c560b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(docs, model=model, embed_model=embed_model, chunk_size=5000, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f72e6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f28ea483",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39bd8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9608abe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Query Response*: Paris is the capital and most populous city of France."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"*Query Response*: {response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8ccbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0482c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Query Response*: Machine learning is a subset of artificial intelligence that enables systems to learn from data without explicit programming. It uses algorithms to identify patterns and make predictions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"*Query Response*: {response}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
